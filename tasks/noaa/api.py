import os
import logging
from datetime import datetime

import pandas as pd
import requests

from ftp import download_noaa_files
from references import COUNTRY_AND_TERRITORY_CODES, \
    TERRITORY_ACTIVE_STATIONS_MAP, DATA_DIRECTORY, load_dataset


logging.basicConfig(level=logging.DEBUG)
logging.getLogger("urllib3").setLevel(logging.WARNING)


def get_stations_by_country(country):
    """Get all stations for a given country code.

    Arguments:
        country(str)

    Returns:
        list[str]
    """

    territory_codes = COUNTRY_AND_TERRITORY_CODES.get(country)
    if territory_codes is None:
        raise ValueError('Wrong country code %s', country)

    stations = list()
    for code in territory_codes:
        code_stations = TERRITORY_ACTIVE_STATIONS_MAP.get(code)
        if code_stations is not None:
            stations.extend(code_stations)

    return stations


def get_request_urls(country, start_date, end_date=None):
    """Encodes the parameters the URL to make a GET request

    Arguments:
        country(str): FIPS Country code
        start_date(datetime)
        end_date(datetime): Defaults to today

    Returns:
        str
    """

    base_url = 'https://www.ncei.noaa.gov/access/services/data/v1?dataset=daily-summaries'

    if end_date is None:
        end_date = datetime.now()
    start = start_date.date().isoformat()
    end = end_date.date().isoformat()

    stations_list = get_stations_by_country(country)
    if len(stations_list) < 10:
        stations = ','.join(stations_list)
        return [f'{base_url}&stations={stations}&startDate={start}&endDate={end}&format=json']
    
    else:
        chunked_station_list = [stations_list[i:i + 15] for i in range(0, len(stations_list), 15)]
        return [
            f'{base_url}&stations={",".join(chunk)}&startDate={start}&endDate={end}&format=json'
            for chunk in chunked_station_list
        ]


def get_parse_response(urls):
    """Calls the urls in urls, return responses and errors

    Arguments:
        urls(list[str]): Urls as generated by `get_request_urls`.

    Returns:
        tuple[list[dict], list[Exception]]:
            The first element of the tuple is a list of dictionary with all the responses.
            The second element is a list with all the exceptions raised during the calls.    
    """

    results = list()
    errors = list()

    total = len(urls) - 1
    for i, url in enumerate(urls):
        logging.debug('Making request %s / %s', i, total)
        response = requests.get(url)
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError as e: 
            errors.append({
                'url': url,
                'error': e
            })
            continue

        results.extend(response.json())

    return results, errors


def noaa_worldwide_api(countries, start_date, end_date=None, enrich_data=True):
    """Get data from NOAA API.

    Arguments:
        countries(list[str]): List of FIPS country codes to retrieve.
        start_date(datetime)
        end_date(datetime)
        enrich_data(bool): Add metadata from the metereological stations

    Returns:
        tuple[list[dict], list[Exception]]
    """
    if not os.path.isfile(f'{DATA_DIRECTORY}/stations_metadata.txt'):
        download_noaa_files(large_files=False)

    result = list()
    for country in countries:
        logging.info('Requesting data for %s', country)
        urls = get_request_urls(country, start_date, end_date)
        country_results, errors = get_parse_response(urls)

        if errors:
            logging.INFO('The following errors where found during the operation:')
            for error in errors:
                logging.INFO(error)

        result.extend(country_results)

    data = pd.DataFrame(result)
    stations = load_dataset('stations')
    data.merge(stations, how='left', left_on='STATION', right_on='ID')
    data = data.merge(stations, how='left', left_on='STATION', right_on='ID')

    del data['ID']
    del data['STATE']

    columns = [
        'DATE', 'STATION', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME',
        'GSN FLAG', 'HCN/CRN FLAG', 'WMO ID', 'TMAX', 'TAVG', 'TMIN', 'PRCP', 'SNWD'
    ]
    return data[columns]
